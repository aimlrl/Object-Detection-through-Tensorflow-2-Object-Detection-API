{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This code is right now executed in google colab. The date as of completing this code is 14/02/2022. Right now, this code will run without any problems while setting the runtime on TPU. If you set the runtime on GPU, this code won't work right now. \n",
        "\n",
        "# Yes, it may happen in future that the problem prevalent with setting runtine as GPU, gets solved so if you are trying to execute this code after let's say a month or two, please first try setting up the runtime to GPU because on GPU, it gets trained faster and it may be the case that it gets executed without any problems. On TPU runtime, it gets trained slowly. "
      ],
      "metadata": {
        "id": "Mswu9MUj4Twl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The working link to download the dataset has been provided inside the code. "
      ],
      "metadata": {
        "id": "uaqT8gLr5xpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement:\n",
        "\n",
        "##### Given images of the different cigarrette packets on different aisles across different grocery stores, you have to train an object detection neural network to perform object detection on cigarrette packets of different brands so that the number of cigarrette packets of different brands can be counted and hence their availability can be tracked across different grocery stores and therefore better decisions can be taken regarding the supply chain of different brands of cigarette packets so as to ensure their continuous availability to the customer.   "
      ],
      "metadata": {
        "id": "VWpu3aGV6Ivw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndvo5tMrwbKK"
      },
      "source": [
        "# Let's navigate inside the root directory of google drive. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SED0paoUwK0S"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's create a directory to clone all the files and folders of Tensorflow 2.0 Object Detection API. "
      ],
      "metadata": {
        "id": "rheXGZOA2pJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir tf2_od_api"
      ],
      "metadata": {
        "id": "USeyH2Ez20Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9yrlWm3wzFH"
      },
      "source": [
        "# Let's now clone the repository of Tensorflow 2.0 Object Detection API files inside this directory. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api"
      ],
      "metadata": {
        "id": "6YGOMuB73A0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doyM4f5DIppW"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV2m-UZ_xT9o"
      },
      "source": [
        "# Let's now follow the steps to install Tensorflow 2.0 Object Detection API. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAy93i8_Iw0p"
      },
      "outputs": [],
      "source": [
        "! sudo apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "! pip install Cython contextlib2 pillow lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGaCtlVMJR7q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYTHONPATH\"] += ':/content/models/research/:/content/models/research/slim/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2FTC1T3xgSe"
      },
      "source": [
        "# Let's now navigate inside a specific directory named \"research\" inside the installtion directory of Tensorflow 2.0 Object Detection API, tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGAoiK2HJZhu"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/models/research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qXdIHPQJp5a"
      },
      "outputs": [],
      "source": [
        "! protoc object_detection/protos/*.proto --python_out=."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAk3RHfox0Bx"
      },
      "source": [
        "# Let's again navigate back into the root directory of google drive. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjCGacKcJ299"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhhfEzo0x7td"
      },
      "source": [
        "# Let's clone the MS COCO API repository in the root directory of google drive. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKqM9uxSJ-Py"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/cocodataset/cocoapi.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06vKcY03yGL7"
      },
      "source": [
        "# Let's navigate into the directory of MS COCO API. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMiIdIaWKA77"
      },
      "outputs": [],
      "source": [
        "cd cocoapi/PythonAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20EucIYoyMSP"
      },
      "source": [
        "# Let's now start the installation of MS COCO API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y40q0jpAKNbp"
      },
      "outputs": [],
      "source": [
        "! make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agOVxn1HKQrL"
      },
      "outputs": [],
      "source": [
        "cp -r pycocotools /content/drive/MyDrive/tf2_od_api/models/research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbIfWP00yUGr"
      },
      "source": [
        "# Let's navigate back into the \"research\" directory inside installation directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FASIFcoAKcSS"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/models/research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3udD2wXvyfzY"
      },
      "source": [
        "# Let's copy some files from this directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EbQMmM9KiU0"
      },
      "outputs": [],
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lk5CuF2KqMp"
      },
      "outputs": [],
      "source": [
        "! python -m pip install --use-feature=2020-resolver ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69p_mG9myuwY"
      },
      "source": [
        "# Let's now check that whether the installtion of our Tensorflow 2 Object Detection API is successful or not. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4aiHm9gKuir"
      },
      "outputs": [],
      "source": [
        "! python object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCkN3vNIzKq3"
      },
      "source": [
        "# The \"OK\" at the end signifies that the installation of our Tensorflow 2 Object Detection API has been successful. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYZ2xDdRL6DE"
      },
      "source": [
        "# As you can see above the installation of Tensorflow 2 Object Detection API has been succeeded. Now, we have to train our desired neural network model to detect objects in images of our dataset.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjI9smUEMazl"
      },
      "source": [
        "# So firstly, please navigate to the installtion directory of the API.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtA08S3aLbBL"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G6SEcGgz9QC"
      },
      "source": [
        "# Let's first create a directory named \"workspace\" inside our navigated directory of installation. In this directory of \"workspace\", we will be saving the training configurations of different neural network archirectures on different datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B9_TA970VNg"
      },
      "outputs": [],
      "source": [
        "! mkdir workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8UFuBqg0dBL"
      },
      "source": [
        "# Now, inside this workspace directory, we will be creating the directories for training configurations on different datasets. A different dataset will be having different directory. Now, because we will be here performing object detection on shelf images, so let's create a directory named \"shelf_objects_detection\" inside this directory (workspace). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4kTByVf1IHB"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3mzDiXb1NG0"
      },
      "outputs": [],
      "source": [
        "! mkdir ciggs_images_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usfauhe31WhL"
      },
      "source": [
        "# Now, every such directory will consist of all the details of training configurations related to object detection for a specific dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYfjU_kH1kiq"
      },
      "source": [
        "# Let's create a directory inside \"shelf_objects_detection\", named \"images\" inside which we will be downloading our training as well as testing datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDC1hGG719C3"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99wvaOH-2Faa"
      },
      "outputs": [],
      "source": [
        "! mkdir images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs9hAXIJ2Nxe"
      },
      "source": [
        "# Now, let's download our dataset into this directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06b2jOiw2V60"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8PR28_022-m"
      },
      "outputs": [],
      "source": [
        "! wget https://storage.googleapis.com/open_source_datasets/ShelfImages.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qadov9cAMjuK"
      },
      "source": [
        "# Now, let's unzip the dataset into this directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rhVdLRYLudN"
      },
      "outputs": [],
      "source": [
        "! tar -xvf /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/images/ShelfImages.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d535_XKYMvPI"
      },
      "source": [
        "# Now create the following directories inside /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection\n",
        "\n",
        "# annotations\n",
        "# exported_models\n",
        "# models\n",
        "# pre_trained_models\n",
        "\n",
        "# Now, please remember that if you are going to use Tensorflow 2 Object Detection API to detect objects in images of some other dataset then you have to create a new directory inside /content/drive/MyDrive/tensorflow_od_api/workspace:\n",
        "\n",
        "# For Example, /content/drive/MyDrive/tf2_od_api/workspace/ex_dark\n",
        "\n",
        "# and the rest of the directory struture will remain the same. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY02tirT48T8"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9gMEuFt5ASF"
      },
      "outputs": [],
      "source": [
        "! mkdir annotations\n",
        "! mkdir exported_models\n",
        "! mkdir models\n",
        "! mkdir pre_trained_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZUPCO0U5YDp"
      },
      "source": [
        "# Every single directory has some purpose which will be discussing about later on. So, right now we have following directories inside /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection \n",
        "\n",
        "# annotations\n",
        "# exported_models\n",
        "# images\n",
        "# models\n",
        "# pre_trained_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjpqVKX15wS2"
      },
      "source": [
        "# Let's now download the annotations of our Shelf Objects Images dataset in the annotations directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JGJGYLEMswP"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1X_o4VrSs06"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/gulvarol/grocerydataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjr6K2GT9-Rd"
      },
      "outputs": [],
      "source": [
        "! python -m pip uninstall opencv-python-headless==4.5.5.62\n",
        "! python -m pip install opencv-python-headless==4.1.2.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHX2RyegSwBb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import io\n",
        "import tensorflow.compat.v1 as tf\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util, label_map_util\n",
        "from collections import namedtuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEiOd2PupBY-"
      },
      "outputs": [],
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RvR46kub1sw"
      },
      "source": [
        "# Now, let's create our label map file. But the question arrises is what is label map file ? Label map file will consist of dictionaries for different classes of objects which can be detected in an image. The extension of this file is .pbtxt. Each dictionary will consist of two key value pairs, where first key value pair maps the 'id' variable to the class label of the object and the second key value pair maps the 'name' variable to the name of the object. A sample of a dictionary for an object in label map looks like this: \n",
        "\n",
        "# item {\n",
        "#     id: 1\n",
        "#     name: \"Category 1 Object\"\n",
        "# }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDXIPOVvee05"
      },
      "source": [
        "# As there are 11 different objects in our shelf images dataset, therefore there will be 11 such dictionaries written in this label_map.pbtxt file. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7q-0FcofCME"
      },
      "source": [
        "# This label_map.pbtxt file will be written inside the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/annotations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp /content/drive/MyDrive/label_map.pbtxt /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/annotations/"
      ],
      "metadata": {
        "id": "c5D0WuduBMVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuJsQDt9gTVY"
      },
      "source": [
        "# We have created the label_map.pbtxt file and written it inside the above mentioned directory. Now, let's load this file and fetch the dictionary from the file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9zX8yjTTJy4"
      },
      "outputs": [],
      "source": [
        "label_map = label_map_util.load_labelmap(\"/content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/annotations/label_map.pbtxt\")\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucXrbJrIg-Nt"
      },
      "outputs": [],
      "source": [
        "label_map_dict_copy = dict()\n",
        "\n",
        "for k,v in label_map_dict.items():\n",
        "  label_map_dict_copy[v] = k\n",
        "\n",
        "label_map_dict = label_map_dict_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4RPqrovhDvw"
      },
      "outputs": [],
      "source": [
        "label_map_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W63QEb7Zhpw1"
      },
      "source": [
        "# Let's navigate back to the root directory of google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfo2IPNLhfT_"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jFfMO-Zh1ya"
      },
      "source": [
        "# Let's write some functions to create .tfrecord files to store our examples in the form of images as well as it's ground truth labels in the form of ground truth bounding boxes as well as ground truth class labels. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQa3eJHXhyzq"
      },
      "outputs": [],
      "source": [
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIHXM87tifaB"
      },
      "outputs": [],
      "source": [
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(label_map_dict[row['gt_labels']].encode('utf8'))\n",
        "        classes.append(row['gt_labels'])\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY7KqjKfimOU"
      },
      "outputs": [],
      "source": [
        "training_data_writer = (tf.python_io.TFRecordWriter(path=\"/content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/annotations/training_imgs.record\"))\n",
        "testing_data_writer = (tf.python_io.TFRecordWriter(path=\"/content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/annotations/testing_imgs.record\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcAbjq2bjzZO"
      },
      "outputs": [],
      "source": [
        "annotations_df = pd.read_csv(\"/content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/annotations/grocerydataset/annotations.csv\",\n",
        "                             header=None, names=[\"file_name\",\"xmin\",\"ymin\",\"xmax\",\"ymax\",\"gt_labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTKJrVagkezV"
      },
      "outputs": [],
      "source": [
        "annotations_df['gt_labels'] = annotations_df['gt_labels'].apply(lambda x: x+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P2TUQTRkkU4"
      },
      "outputs": [],
      "source": [
        "annotations_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zDGkiVGkoea"
      },
      "outputs": [],
      "source": [
        "different_classes = annotations_df['gt_labels'].unique()\n",
        "print(different_classes)\n",
        "print(len(different_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzOBNMiPnJEG"
      },
      "source": [
        "# Let's determine all the file names inside the testing folder of our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4FeAEErmzKB"
      },
      "outputs": [],
      "source": [
        "testing_imgs = os.listdir(\"/content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/images/ShelfImages/test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLbm58mJnUMk"
      },
      "source": [
        "# As our dataset annotations consist of annotations of all the training as well as testing images, therefore it becomes important to seperate out annotations of training as well as testing images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoJiinwNkyi_"
      },
      "outputs": [],
      "source": [
        "training_data_annotations = list()\n",
        "testing_data_annotations = list()\n",
        "\n",
        "for i in range(len(annotations_df)):\n",
        "\n",
        "  if annotations_df.iloc[i,0] in testing_imgs:\n",
        "    testing_data_annotations.append(list(annotations_df.iloc[i,:]))\n",
        "  else:\n",
        "    training_data_annotations.append(list(annotations_df.iloc[i,:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMzWF6zJnD_U"
      },
      "outputs": [],
      "source": [
        "training_data_annotations_df = pd.DataFrame(data=training_data_annotations,columns=annotations_df.columns)\n",
        "testing_data_annotations_df = pd.DataFrame(data=testing_data_annotations,columns=annotations_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYzUcycynqLh"
      },
      "outputs": [],
      "source": [
        "training_data_annotations_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xreqeq1en0QG"
      },
      "outputs": [],
      "source": [
        "testing_data_annotations_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt0mlp0Hn7fD"
      },
      "source": [
        "# We have created all the functions to create .tfrecord files as well as also create seperate training as well as testing data annotations. Now, let's start the procedure to create .tfrecord files using the above functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkiPJvf5oUQX"
      },
      "source": [
        "# Let's create training as well as testing examples. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AysxTMM4n3PH"
      },
      "outputs": [],
      "source": [
        "grouped_training_data = split(df=training_data_annotations_df,group=\"file_name\")\n",
        "grouped_testing_data = split(df=testing_data_annotations_df,group=\"file_name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlMqo9o5obvr"
      },
      "outputs": [],
      "source": [
        "training_data_base_path = \"/content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/images/ShelfImages/train\"\n",
        "testing_data_base_path = \"/content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/images/ShelfImages/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvwX7n_8oo9T"
      },
      "outputs": [],
      "source": [
        "for single_img_group in grouped_training_data:\n",
        "\n",
        "  tf_example = create_tf_example(group=single_img_group,path=training_data_base_path)\n",
        "  training_data_writer.write(record=tf_example.SerializeToString())\n",
        "\n",
        "training_data_writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW4OOkJ4pmiJ"
      },
      "outputs": [],
      "source": [
        "for single_img_group in grouped_testing_data:\n",
        "\n",
        "  tf_example = create_tf_example(group=single_img_group,path=testing_data_base_path)\n",
        "  testing_data_writer.write(record=tf_example.SerializeToString())\n",
        "\n",
        "testing_data_writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjvLczDkqrhX"
      },
      "outputs": [],
      "source": [
        "images_dataset = tf.data.TFRecordDataset(\"/content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/annotations/training_imgs.record\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anqG-lEXrIkW"
      },
      "outputs": [],
      "source": [
        "out_img_features = {\n",
        "        'image/height': tf.io.FixedLenFeature(shape=[],dtype=tf.int64),\n",
        "        'image/width': tf.io.FixedLenFeature(shape=[],dtype=tf.int64),\n",
        "        'image/filename': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
        "        'image/source_id': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
        "        'image/encoded': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
        "        'image/format': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
        "        'image/object/bbox/xmin': tf.io.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/xmax': tf.io.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymin': tf.io.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymax': tf.io.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/class/text': tf.io.FixedLenSequenceFeature(shape=[],dtype=tf.string,allow_missing=True),\n",
        "        'image/object/class/label': tf.io.VarLenFeature(dtype=tf.int64),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDyBaI5erNlY"
      },
      "outputs": [],
      "source": [
        "def parse_image(example_proto):\n",
        "  return tf.io.parse_single_example(serialized=example_proto,features=out_img_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oimick7yrS-M"
      },
      "outputs": [],
      "source": [
        "import IPython.display as display\n",
        "\n",
        "parsed_image_dataset = images_dataset.map(parse_image)\n",
        "counter = 0\n",
        "\n",
        "for image_out_features in parsed_image_dataset:\n",
        "\n",
        "  if counter == 2:\n",
        "    break\n",
        "\n",
        "  print(image_out_features[\"image/height\"])\n",
        "  print(image_out_features[\"image/width\"])\n",
        "  print(image_out_features[\"image/filename\"])\n",
        "  print(image_out_features[\"image/source_id\"])\n",
        "  print(image_out_features[\"image/format\"])\n",
        "  print(image_out_features[\"image/object/bbox/xmin\"])\n",
        "  print(image_out_features[\"image/object/bbox/xmax\"])\n",
        "  print(image_out_features[\"image/object/bbox/ymin\"])\n",
        "  print(image_out_features[\"image/object/bbox/ymax\"])\n",
        "  print(image_out_features[\"image/object/class/text\"])\n",
        "  print(image_out_features[\"image/object/class/label\"])\n",
        "\n",
        "  image_out = image_out_features[\"image/encoded\"].numpy()\n",
        "  display.display(display.Image(data=image_out))\n",
        "\n",
        "  counter = counter + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZxSTzL8r0mO"
      },
      "source": [
        "# Now, we should train our object detection neural network and the neural network which we have chosen from Tensorflow Object Detection Zoo, is: \n",
        "\n",
        "# ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.tar.gz\n",
        "\n",
        "# Therefore, we are going to download the zip file of this model to /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/pre_trained_models and fine tune it on our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSx92Eh_roYH"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/pre_trained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIwJ1_xFtTKw"
      },
      "outputs": [],
      "source": [
        "! wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlbPuOWltfw4"
      },
      "source": [
        "# Let's now unzip this file at the same location. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-Juu_uetZnz"
      },
      "outputs": [],
      "source": [
        "! tar -xvf /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/pre_trained_models/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axYa-j73_YNl"
      },
      "source": [
        "# Now, suppose we wish to use some other pre-trained model to train our object detector on the same dataset then we can download other pre-trained model's tarbar files into the \"pre_trained_models\" directory and untar it here only.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h4aMBg-ABDT"
      },
      "source": [
        "# Now, let's navigate to the /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/models and create a new directory for our training job for fine tuning our currently downloaded architecture of SSD. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzsvZQ7XAVcm"
      },
      "source": [
        "# Let's first navigate to the above directory and create a seperate directory for our training job inside the above mentione directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JWWoR29tphr"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT5vAagpAjpc"
      },
      "outputs": [],
      "source": [
        "! mkdir resnet50_v1_ssd_fpn_1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWl4AF49A6Kp"
      },
      "source": [
        "# Inside the above created directory, we have to copy the pipeline configuration file (pipeline.config) of the downloaded model inside /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/pre_trained_models/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8\n",
        "\n",
        "# to \n",
        "\n",
        "# /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/models/resnet50_v1_ssd_fpn_1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUw2PJBFA3X3"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/pre_trained_models/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8/pipeline.config /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/models/resnet50_v1_ssd_fpn_1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV3SNTIzC0KZ"
      },
      "source": [
        "# Now, let's modify our copied pipeline.config file inside /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection/models/resnet50_v1_ssd_fpn_1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22giBuq7DwrB"
      },
      "source": [
        "# And change the following variables in pipeline.config according to your desired configuration:\n",
        "\n",
        "# (line 3) num_classes: <Total number of classes of different objects in our dataset>\n",
        "\n",
        "# (line 131) batch_size: <Our desired batch size on which we want to fine tune our pre-trained network on our dataset, if we have high end GPU and good amount of memory then keep it to the default value of 8, otherwise reduce it. We will set it to 4> \n",
        "\n",
        "# (line 161) fine_tune_checkpoint: <path of the directory where pre-trained weights of our Neural Network are present in the form of checkpoints and they are going to be fine tuned on our dataset by further training our network on our desired dataset> \n",
        "\n",
        "# (line 167) fine_tune_checkpoint_type: <\"detection\">\n",
        "\n",
        "# (line 168) use_bfloat16: <Set this variable's value to false if not training on a TPU>\n",
        "\n",
        "# (line 172) label_map_path: <path of the directory where label_map.pbtxt file is written>\n",
        "\n",
        "# (line 174) input_path: <path of the directory where TFrecord file of the training data is written>\n",
        "\n",
        "# (line 178) metrics_set: <\"coco_detection_metrics\">\n",
        "\n",
        "# (line 179) use_moving_averages: <\"false\">\n",
        "\n",
        "# (line 182) label_map_path: <path of the directory where label_map.pbtxt file is written>\n",
        "\n",
        "# (line 186) input_path: <path of the directory where TFrecord file of the testing data is written>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftmGKTJtPDK4"
      },
      "source": [
        "# Let's change the directory to root directory of our training configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zvZxxz_Crqc"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p58LI8_4PU1L"
      },
      "source": [
        "# Let's copy the file named \"model_main_tf2.py\" from /content/drive/MyDrive/tf2_od_api/models/research/object_detection/model_main_tf2.py \n",
        "\n",
        "# to \n",
        "\n",
        "# /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection\n",
        "\n",
        "# because now we need this script to fine tune our pre-trained neural network on our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_BqIwnYQAAn"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/tf2_od_api/models/research/object_detection/model_main_tf2.py /content/drive/MyDrive/tf2_od_api/workspace/ciggs_images_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDgTkzdTu-RQ"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX7nTE4OvXQd"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3Xyg_LyPN6t"
      },
      "outputs": [],
      "source": [
        "! python model_main_tf2.py --model_dir=models/resnet50_v1_ssd_fpn_1024 --pipeline_config_path=models/resnet50_v1_ssd_fpn_1024/pipeline.config"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# As we have already trained our model and the trained parameters of our model have been saved in the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/models/resnet50_v1_ssd_fpn_1024/train\n",
        "\n",
        "# Now, we should use these trained parameters to perform inference on our unseen data. \n",
        "\n",
        "# Now, in order to do that first we have to export our trained model with trained weights. For that, we have to export our model using a script called exporter_main_v2.py which is located at the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/models/research/object_detection/exporter_main_v2.py\n",
        "\n",
        "# We have to now copy this script from the above location and paste it into the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection\n",
        "\n",
        "# and then run this script."
      ],
      "metadata": {
        "id": "nxxaSbHih5Ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz7Z3JUiQ6ed"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/tensorflow_od_api/models/research/object_detection/exporter_main_v2.py /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection"
      ],
      "metadata": {
        "id": "awuoSchnkmAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, since we have copied the script, let's run the script to export our trained model to the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/exported_models/first_training_instance"
      ],
      "metadata": {
        "id": "t-FbCCtxk1-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/resnet50_v1_ssd_fpn_1024/pipeline.config --trained_checkpoint_dir ./models/resnet50_v1_ssd_fpn_1024 --output_directory ./exported_models/first_training_instance"
      ],
      "metadata": {
        "id": "fi-IXmLfkvc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops\n",
        "from object_detection.utils import visualization_utils as viz\n",
        "from object_detection.utils.label_map_util import create_category_index_from_labelmap\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Wwm7BIZ1mjeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path):\n",
        "  image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(image_data))\n",
        "  width, height = image.size\n",
        "  shape = (height, width, 3)\n",
        "  image = np.array(image.getdata())\n",
        "  image = image.reshape(shape).astype('uint8')\n",
        "  return image"
      ],
      "metadata": {
        "id": "KLtsSG7Lpvty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_image(net, image):\n",
        "  image = np.asarray(image)\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  result = net(input_tensor)\n",
        "  num_detections = int(result.pop('num_detections'))\n",
        "  result = {key: value[0, :num_detections].numpy() for key, value in result.items()}\n",
        "  result['num_detections'] = num_detections\n",
        "  result['detection_classes'] = result['detection_classes'].astype('int64')\n",
        "  if 'detection_masks' in result:\n",
        "    detection_masks_reframed = ops.reframe_box_masks_to_image_masks(result['detection_masks'],result['detection_boxes'],image.shape[0],image.shape[1])\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,tf.uint8)\n",
        "    result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "  return result"
      ],
      "metadata": {
        "id": "v1YpBYw5sU8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_path = \"./annotations/label_map.pbtxt\"\n",
        "category_idx = create_category_index_from_labelmap(labels_path,use_display_name=True)\n",
        "model_path = \"./exported_models/first_training_instance/saved_model\"\n",
        "model = tf.saved_model.load(model_path)\n",
        "test_images = list(glob.glob(\"./images/ShelfImages/test/*.JPG\"))\n",
        "random.shuffle(test_images)\n",
        "test_images = test_images[:16]"
      ],
      "metadata": {
        "id": "KzcYF-jIsdD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_path in test_images:\n",
        "  image = load_image(image_path)\n",
        "  result = infer_image(model, image)\n",
        "  masks = result.get('detection_masks_reframed',None)\n",
        "  viz.visualize_boxes_and_labels_on_image_array(image,result['detection_boxes'],result['detection_classes'],\n",
        "                                                result['detection_scores'],category_idx,instance_masks=masks,\n",
        "                                                use_normalized_coordinates=True,line_thickness=5)\n",
        "  plt.figure(figsize=(24,24))\n",
        "  plt.imshow(image)\n",
        "  plt.savefig(f'detections_{image_path.split(\"/\")[-1]}')"
      ],
      "metadata": {
        "id": "5x-09wX0tC-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y481PfmNuVjc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1Uem6bi2nUajZWhU_JlIb7JkewsfBMlyk",
      "authorship_tag": "ABX9TyOIp1UmRvh8WCSfQIezfg3X"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}